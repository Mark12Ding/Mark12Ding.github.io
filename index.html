<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Shuangrui Ding</title>
<meta name="author" content="Shuangrui Ding">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" type="text/css" href="stylesheet.css">
<link rel="icon" type="image/png" href="images/icon.png">
</head>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shuangrui Ding (丁双睿)</name>
              </p>
              <p>I am a master student at Electrical Engineering Department of Shanghai Jiao Tong University, advised by <a href="https://min.sjtu.edu.cn/xhk.htm">Prof. Hongkai Xiong</a>. Prior to that, I obtained my bachelor degree of <a href="https://cse.engin.umich.edu/academics/undergraduate/computer-science-eng/">Computer Science</a> at University of Michigan, with a dual degree of <a href="https://www.ji.sjtu.edu.cn/academics/undergraduate-program/degrees-programs/electrical-and-computer-engineering/">Electrical and Computer Engineering</a> at Shanghai Jiao Tong University in 2021. 
              </p>
              <p>
                During my undergraduate, I have been a member in <a href="http://foreseer.si.umich.edu/">Foreseer</a> at Umich, where I was advised by <a href="http://www-personal.umich.edu/~qmei">Prof. Qiaozhu Mei</a> and mentored by <a href="http://www.jiaqima.com/">Jiaqi Ma</a>. I also interned at Tencent AI Lab, lead by <a href="http://juewang725.github.io/">Jue Wang</a>. 
              </p>
              <p>
                I'm interested in computer vision and deep learning. Currently, self-supervised learning on spatio-temporal data excites me. 
              </p>
              <p>
                Please drop me an email if you are interested in corporation with we.  
              </p>
              <p style="text-align:center">
                <a href="mailto:dsr1212@sjtu.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/CV_DingShuangrui.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=jmFZZYMAAAAJ">Google Scholar</a>&nbsp/&nbsp
                <a href="https://github.com/Mark12Ding">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/selfie.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/selfie_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <strong>[Jun. 2022]</strong> </b> Our paper <em>Dual Contrastive Learning for Spatio-temporal Representation</em> was accepted at <a href="https://2022.acmmm.org/">ACM MM 2022</a>.
              </p>
              <p>
                <strong>[Mar. 2022]</strong> </b> Our paper <em>Motion-aware Contrastive Video Representation Learning via Foreground-background Merging
                    </em> was accepted at <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Motion-Aware_Contrastive_Video_Representation_Learning_via_Foreground-Background_Merging_CVPR_2022_paper.html">CVPR 2022</a>.
              </p>
              <p>
                <strong>[Jul. 2021]</strong> </b> Our paper <em>Enhancing Self-Supervised Video Representation Learning via Multi-Level Feature Optimization
                    </em> was accepted at <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Qian_Enhancing_Self-Supervised_Video_Representation_Learning_via_Multi-Level_Feature_Optimization_ICCV_2021_paper.html">ICCV 2021</a>.
              </p>
              <!-- <p>
                <strong>[Sep. 2020]</strong> </b> Our paper <em>Towards More
                     Practical Adversarial Attacks on Graph Neurel Networks
                    </em> was accepted at <a href="https://papers.nips.cc/paper/2020/hash/32bb90e8976aab5298d5da10fe66f21d-Abstract.html">NeurIPS 2020</a>.
              </p> -->
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:baseline">
          <heading>Publications(&#42; equal contribution)</heading>
        </td>
      </tr>
    </tbody></table>
    
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/MM2022.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Dual Contrastive Learning for Spatio-temporal Representation</papertitle>
              <br>
              <strong>Shuangrui Ding</strong>,
              <a href="https://shvdiwnkozbw.github.io/">Rui Qian</a>, <a href="https://min.sjtu.edu.cn/xhk.htm">Hongkai Xiong</a>
              <br>
        <em>ACM MM</em>, 2022 
              <br>
              More to come. Stay tuned.
              <p></p>
              <p> A novel dual contrastive formulation is presented to decouple the static/dynamic features and thus mitigate the background bias.</p>
            </td>
      </tr> 
      <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/CVPR2022.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Motion-aware Contrastive Video Representation Learning via Foreground-background Merging</papertitle>
              <br>
              <strong>Shuangrui Ding</strong>,
              Maomao Li, Tianyu Yang, <a href="https://shvdiwnkozbw.github.io/">Rui Qian</a>, Haohang Xu, Qingyi Chen, Jue Wang, <a href="https://min.sjtu.edu.cn/xhk.htm">Hongkai Xiong</a>
              <br>
        <em>CVPR</em>, 2022 
              <br>
              <a href="https://mark12ding.github.io/project/CVPR22_FAME/">Project page</a>
              / 
              <a href="https://arxiv.org/abs/2109.15130/">arXiv</a> 
              / 
              <a href="https://github.com/Mark12Ding/FAME">code</a>
              /
              <a href="https://mp.weixin.qq.com/s/eZ_8qyVa7L8-n2RHBge0mQ">Chinese coverage</a>
              <p></p>
              <p>Mitigate the background bias in self-supervised video representation learning via copy-pasting the foreground onto the other backgrounds.</p>
            </td>
      </tr>
      <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='iccv_image'>
                  <img src='images/iccv2.jpeg' width="160"></div>
                <img src='images/iccv.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function iccv_start() {
                  document.getElementById('iccv_image').style.opacity = "1";
                }

                function iccv_stop() {
                  document.getElementById('iccv_image').style.opacity = "0";
                }
                iccv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Enhancing Self-supervised Video Representation Learning via Multi-level Feature Optimization</papertitle>
              <br>
              <a href="https://shvdiwnkozbw.github.io/">Rui Qian</a>, Yuxi Li, Huabin Liu, John See,
              <strong>Shuangrui Ding</strong>, Xian Liu, Dian Li, 
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>ICCV</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2108.02183">arXiv</a> / 
              <a href="https://github.com/shvdiwnkozbw/Video-Representation-via-Multi-level-Optimization">code</a>
              <p></p>
              <p>Self-supervised video representation learning from the perspective of both high-level semantics and lower-level characteristics</p>
            </td>
      </tr>
      <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/NIPS2020.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Towards More Practical Adversarial Attacks on Graph Neurel Networks</papertitle>
              <br>
              <a href="http://www.jiaqima.com/">Jiaqi Ma*</a>,
              <strong>Shuangrui Ding*</strong>,
              <a href="http://www-personal.umich.edu/~qmei">Qiaozhu Mei</a>
              <br>
        <em>NeurIPS</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2006.05057">arXiv</a>
        /
              <a href="https://docs.google.com/presentation/d/18AqRjgTz8d2sSCE_cUgTHYzs2mWhOug-U5HZWBUU67o/edit?usp=sharing">slides</a>
        /    
              <a href="https://slideslive.com/38931435/practical-adversarial-attacks-on-graph-neural-networks">video
              </a>
        /
              <a href="https://github.com/Mark12Ding/GNN-Practical-Attack">code
              </a>
              <p></p>
              <p>Exploiting the structural inductive biases of GNNs, the restricted black-box adversarial attacks can be conducted effectively.</p>
            </td>
      </tr> 
      </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards</heading>
              <p>
                <strong>Shanghai Excellent Graduate</strong> (Top 5%), Shanghai Municipal Education Commission. 2021 
              </p>
              <p>
                <strong>Finalist winner</strong> (Top 0.3%), Mathematical Contest in Modeling. 2019 
              </p>
              <p>
              <strong>Nation Scholarship</strong> (Top 2%), Ministry of Education of China. 2018 
              </p>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Professional Services</heading>
              <p>
                  <li>
                      Reviewer: ECCV'22.
                  </li>
              </p>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Misc</heading>
              <p>
                1. My favorite sports is soccer. I was the captain of UM-SJTU JI soccer team during season 2018. Besides, I am a super fan of Manchester City in Premier League. C'mon City!
              </p>
              <p>
                2. I am proud that I have graudated from the competition class at Hangzhou No.2 High school, where I make friends with so many talented students and prestigious teachers. 
              </p>
              <p>
                3. It is worth mentioning that <a href="https://shvdiwnkozbw.github.io/">Rui</a> is my best friend and has motivated me forward for over ten years as my role model. Best wishes and good luck! 
              </p>
            </td>
          </tr>
        </tbody></table>
<!--     <table width="50%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
            <tr>
                <td style="padding:0px">
                    <br>
                    <br>
                    <div>
                        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=7lqf9KytMX7LblPx6VWALqJ3PbQAiEEYCwUq_KvZgBI'></script>
                    </div>
                </td>
            </tr>
        </tbody>
    </table> -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
            <tr>
                <td style="padding:0px">
                    <p font-size:small;>
                        <br>
                        <br>
                        <div style="float:left;">
                            Updated at Jun. 2022
                        </div>
                        <div style="float:right;">
                            Thanks <a href="https://jonbarron.info">Jon Barron</a> for this amazing template.
                        </div>
                        <br>
                        <br>        
                    </p>                           
                </td>
            </tr>
        </tbody>
    </table>
    </body>
</html>